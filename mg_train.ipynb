{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import scipy.io as sio\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"mps\") # apple silicon\n",
    "# device = torch.device(\"cpu\") # cpu\n",
    "# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\") # nvidia\n",
    "print(f'device: {device}')\n",
    "\n",
    "def to_tensor(x, device=torch.device(\"cpu\")): return torch.tensor(x, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best MSE loss: 0.087"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download datasets from gdrive\n",
    "# import gdown\n",
    "# gdown.download(id=\"1-5KP7_OYIvDD_QXvIr5sDihVxZx1qJCN\", output='data/ITER_like_equilibrium_dataset_sample.mat', quiet=False)\n",
    "# gdown.download(id=\"1Gn_OrMzxPRkTk-i77--HiWmWZyd8i8ue\", output='data/ITER_like_equilibrium_dataset.mat', quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = \"mg_data/mg_planet.pth\"\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 3e-3\n",
    "USE_CURRENTS = True\n",
    "USE_PROFILES = False\n",
    "USE_MAGNETIC = True\n",
    "INPUT_SIZE = int(USE_CURRENTS)*14 + int(USE_PROFILES)*202 + int(USE_MAGNETIC)*187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_DS_PATH = \"data/ITER_like_equilibrium_dataset_sample.mat\" # sample dataset\n",
    "FULL_DS_PATH = 'data/ITER_like_equilibrium_dataset.mat' # full dataset\n",
    "sample_ds_mat = sio.loadmat(SAMPLE_DS_PATH)\n",
    "full_ds_mat = sio.loadmat(FULL_DS_PATH)\n",
    "print(f\"sample_ds_mat keys: {sample_ds_mat.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mean current: -10183.76, std current: 34209.11\n",
    "- mean magnetic: -0.20, std magnetic: 0.58\n",
    "- mean f_profile: 33.13, std f_profile: 0.28\n",
    "- mean p_profile: 9654.42, std p_profile: 8788.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlaNetDataset(Dataset):\n",
    "    def __init__(self, ds_mat):\n",
    "        # output: magnetic flux, transposed (matlab is column-major)\n",
    "        self.psi = to_tensor(ds_mat[\"DB_psi_pixel_test_ConvNet\"].transpose(0, 2, 1)) # (n, 64, 64)\n",
    "        # inputs: radial and vertical position of pixels (for plotting only rn) + currents + measurements + profiles \n",
    "        self.rr_pix = ds_mat[\"RR_pixels\"] # radial position of pixels (64, 64)\n",
    "        self.zz_pix = ds_mat[\"ZZ_pixels\"] # vertical position of pixels (64, 64)\n",
    "        self.currs = ds_mat[\"DB_coils_curr_test_ConvNet\"] # input currents (n, 14)\n",
    "        self.magn_meas = ds_mat[\"DB_meas_Bpickup_test_ConvNet\"] # input magnetic measurements (n, 187)\n",
    "        self.f_profile = ds_mat[\"DB_f_test_ConvNet\"] # input profiles (n, 101)\n",
    "        self.p_profile = ds_mat[\"DB_p_test_ConvNet\"] # input profiles (n, 101)\n",
    "        inputs = [] # add the normalized inputs to the list\n",
    "        if USE_CURRENTS: inputs.append((to_tensor(self.currs)+10183)/34209) # (n, 14)\n",
    "        if USE_MAGNETIC: inputs.append((to_tensor(self.magn_meas)+0.2)/0.58) # (n, 187)\n",
    "        if USE_PROFILES: inputs.append(torch.cat(((to_tensor(self.f_profile)-33.13)/0.28, (to_tensor(self.p_profile)-9654)/8788), 1)) # (n, 202)\n",
    "        self.inputs = torch.cat(inputs, 1) # (n, 403)\n",
    "    def __len__(self): return len(self.psi)\n",
    "    def __getitem__(self, idx): return self.inputs[idx], self.psi[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset\n",
    "ds = PlaNetDataset(sample_ds_mat)\n",
    "print(f\"Dataset length: {len(ds)}\")\n",
    "print(f\"Input shape: {ds[0][0].shape}\")\n",
    "print(f\"Output shape: {ds[0][1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PlaNet(nn.Module): # simple fully connected neural network > weak > loss:33 > converges to a constant\n",
    "#     def __init__(self):\n",
    "#         super(PlaNet, self).__init__()\n",
    "#         self.n = 8\n",
    "#         self.fc1 = nn.Linear(INPUT_SIZE, self.n)\n",
    "#         self.fc2 = nn.Linear(self.n, self.n)\n",
    "#         self.fc3 = nn.Linear(self.n, 64*64)\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = torch.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         x = x.view(-1, 64, 64)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PlaNet(nn.Module): # transpose convolutional neural network > stronger, fast, but artifacts\n",
    "#     def __init__(self):\n",
    "#         super(PlaNet, self).__init__()\n",
    "#         self.n = n = 4\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(INPUT_SIZE, 8*n),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(8*n, 16*n),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "#         self.unconv = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(16*n, 8*n, kernel_size=3),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm2d(8*n), # batch normalization\n",
    "#             nn.ConvTranspose2d(8*n, 4*n, kernel_size=3, stride=2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.ConvTranspose2d(4*n, 2*n, kernel_size=3, stride=2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.ConvTranspose2d(2*n, n, kernel_size=3, stride=2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.ConvTranspose2d(n, 1, kernel_size=4, stride=2),\n",
    "#         )\n",
    "#     def forward(self, x):\n",
    "#         x = self.fc(x)\n",
    "#         x = x.view(-1, 16*self.n, 1, 1)\n",
    "#         x = self.unconv(x)\n",
    "#         x = x.view(-1, 64, 64)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlaNet(nn.Module): # upsample convolutional neural network > slower > but smoother\n",
    "    def __init__(self):\n",
    "        super(PlaNet, self).__init__()\n",
    "        self.interp = 'bilinear' # 'nearest' or 'bilinear'\n",
    "        self.n = n = 2\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(INPUT_SIZE, 8*n),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8*n, 16*n),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.unconv = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=4, mode=self.interp),\n",
    "            nn.Conv2d(16*n, 8*n, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(8*n), # batch normalization\n",
    "            nn.Upsample(scale_factor=2, mode=self.interp),\n",
    "            nn.Conv2d(8*n, 4*n, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode=self.interp),\n",
    "            nn.Conv2d(4*n, 2*n, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode=self.interp),\n",
    "            nn.Conv2d(2*n, n, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode=self.interp),\n",
    "            nn.Conv2d(n, 1, kernel_size=3, padding=1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, 16*self.n, 1, 1)\n",
    "        x = self.unconv(x)\n",
    "        x = x.view(-1, 64, 64)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "model = PlaNet()\n",
    "x = torch.randn(1, INPUT_SIZE)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "y = model(x)\n",
    "print(f\"Output shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "A = np.zeros((N, N))\n",
    "for k in range(N):\n",
    "    for n in range(N):\n",
    "        if n > k: A[n,k] = (2*n+1)**0.5 * (2*k+1)**0.5\n",
    "        if n == k: A[n,k] = n+1\n",
    "        if n < k: A[n,k] = 0\n",
    "plt.imshow(A)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grad-Shafranov Operator Loss (PINN)\n",
    "μ0 = 4*np.pi*1e-7\n",
    "RRpix, ZZpix = sample_ds_mat[\"RR_pixels\"], sample_ds_mat[\"ZZ_pixels\"]\n",
    "hr, hz = RRpix[0, 1] - RRpix[0, 0], ZZpix[1, 0] - ZZpix[0, 0]\n",
    "RRin, ZZin = RRpix[1:-1,1:-1], ZZpix[1:-1,1:-1]\n",
    "### Filters for GS equation\n",
    "kr = np.array(([0, 0, 0], [1, -2, 1], [0, 0, 0]))*hz**2\n",
    "kz = np.transpose(np.array(([0, 0, 0], [1, -2, 1], [0, 0, 0])))*hr**2\n",
    "alfa = -2*(hr**2 + hz**2)\n",
    "Laplace_kernel = np.array(([0, hr**2/alfa, 0], [hz**2/alfa, 1, hz**2/alfa], [0, hr**2/alfa, 0]))\n",
    "Df_dr_kernel = np.array(([0, 0, 0], [+1, 0, -1], [0, 0, 0]))/(2*hr*alfa)*(hr**2*hz**2)\n",
    "# Gaussian filter to slightly denoise output\n",
    "# Gaussian_kernel = np.array(([1,2,1], [2,4,2], [1,2,1]))/16\n",
    "Gaussian_kernel = np.array(([1,4,7,4,1],[4,16,26,16,4],[7,26,41,26,7],[4,16,26,16,4],[1,4,7,4,1]))/273\n",
    "#convert to tensors\n",
    "tRRconv = to_tensor(RRin).unsqueeze(0).unsqueeze(0)\n",
    "tLaplace_kernel = to_tensor(Laplace_kernel[::-1,::-1].copy()).unsqueeze(0).unsqueeze(0)\n",
    "tDf_dr_kernel = to_tensor(Df_dr_kernel[::-1,::-1].copy()).unsqueeze(0).unsqueeze(0)\n",
    "tGaussian_kernel = to_tensor(Gaussian_kernel[::-1,::-1].copy()).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "# def fun_GSoperator_NN_conv_batch(f):\n",
    "#     Lpsi = F.conv2d(f, tLaplace_kernel)\n",
    "#     Dpsi_dr = F.conv2d(f, tDf_dr_kernel)\n",
    "#     Dpsi_dr = Dpsi_dr / tRRconv\n",
    "#     return (Lpsi[:,:,:,0] - Dpsi_dr[:,:,:,0])*alfa / (hr**2 * hz**2) # GS operator\n",
    "\n",
    "# def fun_GSoperator_NN_conv_smooth_batch(f):\n",
    "#     Lpsi = F.conv2d(f, tLaplace_kernel)\n",
    "#     print(f\"Lpsi shape: {Lpsi.shape}\")\n",
    "#     Dpsi_dr = F.conv2d(f, tDf_dr_kernel)\n",
    "#     print(f\"Dpsi_dr shape: {Dpsi_dr.shape}\")\n",
    "#     Dpsi_dr = Dpsi_dr / tRRconv\n",
    "#     print(f\"Dpsi_dr shape: {Dpsi_dr.shape}\")\n",
    "#     GS_ope = (Lpsi - Dpsi_dr) * alfa / (hr**2 * hz**2)\n",
    "#     # GS_ope = F.conv2d(GS_ope, tGaussian_kernel, padding='same')\n",
    "#     GS_ope = torch.squeeze(GS_ope, dim=-1)\n",
    "#     return GS_ope\n",
    "\n",
    "def fun_GSoperator_conv_batch(f):\n",
    "    Lpsi = F.conv2d(f, tLaplace_kernel)\n",
    "    Dpsi_dr = F.conv2d(f, tDf_dr_kernel)\n",
    "    Dpsi_dr = Dpsi_dr / tRRconv\n",
    "    GS_ope = (Lpsi[:, :, :, 0] - Dpsi_dr[:, :, :, 0]) * alfa / (hr**2 * hz**2)\n",
    "    jphi = -GS_ope / (μ0 * RRin)\n",
    "    return GS_ope, jphi\n",
    "\n",
    "print(f\"tRRconv shape: {tRRconv.shape}\")\n",
    "print(f\"tLaplace_kernel shape: {tLaplace_kernel.shape}\")\n",
    "print(f\"tDf_dr_kernel shape: {tDf_dr_kernel.shape}\")\n",
    "print(f\"tGaussian_kernel shape: {tGaussian_kernel.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test GS operator\n",
    "idx = 10\n",
    "gs_gt = sample_ds_mat[\"DB_res_RHS_pixel_test_ConvNet\"][idx].transpose()\n",
    "psi = sample_ds_mat[\"DB_psi_pixel_test_ConvNet\"][idx].transpose()\n",
    "print(f\"psi shape: {psi.shape}\")\n",
    "# gs_calc = fun_GSoperator_NN_conv_smooth_batch(to_tensor(psi).unsqueeze(0).unsqueeze(0)).squeeze()\n",
    "gs_calc = fun_GSoperator_conv_batch(to_tensor(psi).unsqueeze(0).unsqueeze(0))[0].squeeze()\n",
    "\n",
    "print(f\"gs_gt shape: {gs_gt.shape}\")\n",
    "print(f\"gs_calc shape: {gs_calc.shape}\")\n",
    "\n",
    "#plot the GS operator\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 10))\n",
    "ax[0].imshow(-gs_gt, cmap='inferno')\n",
    "ax[0].set_title(\"GS Operator Ground Truth\")\n",
    "# plot the calculated GS operator\n",
    "ax[1].imshow(gs_calc, cmap='inferno')\n",
    "ax[1].set_title(\"GS Operator Calculated\")\n",
    "#plot psi\n",
    "ax[2].imshow(psi, cmap='inferno')\n",
    "ax[2].set_title(\"Psi Ground Truth\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = torch.randn(1, 1, 3, 3)\n",
    "input = torch.randn(1, 1, 64, 64)\n",
    "output = F.conv2d(input, filter)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = PlaNetDataset(full_ds_mat), PlaNetDataset(sample_ds_mat) # initialize datasets\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True) # initialize DataLoader\n",
    "val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)  \n",
    "model = PlaNet()  # instantiate model\n",
    "model.to(device) # move model to device\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = nn.MSELoss() # Mean Squared Error Loss\n",
    "best_loss = float('inf') # initialize best loss\n",
    "for epoch in range(EPOCHS): \n",
    "    epoch_time = time()\n",
    "    model.train()\n",
    "    trainloss, evalloss = [], []\n",
    "    # for input_currs, psi in tqdm(train_dl, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=False):\n",
    "    for input_currs, psi in train_dl:\n",
    "        input_currs, psi = input_currs.to(device), psi.to(device) # move to device\n",
    "        optimizer.zero_grad()\n",
    "        psi_pred = model(input_currs)\n",
    "        loss = loss_fn(psi_pred, psi)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        trainloss.append(loss.item())\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for input_currs, psi in val_dl:\n",
    "            input_currs, psi = input_currs.to(device), psi.to(device) # move to device\n",
    "            psi_pred = model(input_currs)\n",
    "            loss = loss_fn(psi_pred, psi)\n",
    "            evalloss.append(loss.item())\n",
    "    print(f\"Ep {epoch+1}: Train Loss: {sum(trainloss)/len(trainloss):.4f}, Eval Loss: {sum(evalloss)/len(evalloss):.4f}, Time: {time()-epoch_time:.2f}s,\", end=\" \")\n",
    "    if sum(evalloss)/len(evalloss) < best_loss:\n",
    "        best_loss = sum(evalloss)/len(evalloss)\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        print(\"new best\")\n",
    "    else: print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PlaNet()\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "model.eval()\n",
    "ds = PlaNetDataset(sample_ds_mat)\n",
    "# ds = PlaNetDataset(full_ds_mat)\n",
    "for i in np.random.randint(0, len(ds), 10):  \n",
    "    input_currs, psi = ds[i]\n",
    "    psi_pred = model(input_currs.unsqueeze(0))\n",
    "    psi_pred = psi_pred.detach().numpy().reshape(64, 64)\n",
    "    psi = psi.detach().numpy().reshape(64, 64)\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(15, 5))\n",
    "    ext = [ds.rr_pix.min(), ds.rr_pix.max(), ds.zz_pix.min(), ds.zz_pix.max()]\n",
    "    rr, zz = ds.rr_pix, ds.zz_pix  # radial and vertical positions of pixels\n",
    "    bmin, bmax = np.min([psi, psi_pred]), np.max([psi, psi_pred])\n",
    "    err = np.abs(psi - psi_pred)*100/abs(bmax - bmin)\n",
    "    # err = np.abs(psi - psi_pred)*100/abs((psi + psi_pred)/2)\n",
    "    err_mse = (psi - psi_pred)**2\n",
    "\n",
    "    im0 = axs[0].imshow(psi, extent=ext, vmin=bmin, vmax=bmax)\n",
    "    axs[0].set_title(\"Actual\")\n",
    "    axs[0].set_aspect('equal')\n",
    "    fig.colorbar(im0, ax=axs[0]) \n",
    "\n",
    "    im1 = axs[1].imshow(psi_pred, extent=ext, vmin=bmin, vmax=bmax)\n",
    "    axs[1].set_title(\"Predicted\")\n",
    "    axs[1].set_aspect('equal')\n",
    "    fig.colorbar(im1, ax=axs[1])\n",
    "\n",
    "    im2 = axs[2].imshow(err, extent=ext, vmin=0, vmax=5)\n",
    "    axs[2].set_title(\"Error\")\n",
    "    axs[2].set_aspect('equal')\n",
    "    fig.colorbar(im2, ax=axs[2])\n",
    "\n",
    "    im3 = axs[3].imshow(err_mse, extent=ext, vmin=0, vmax=0.5)\n",
    "    axs[3].set_title(\"MSE\")\n",
    "    axs[3].set_aspect('equal')\n",
    "    fig.colorbar(im3, ax=axs[3])\n",
    "\n",
    "    c0 = axs[4].contour(rr, zz, psi, levels=15, cmap='viridis', linestyles='dashed')\n",
    "    c1 = axs[4].contour(rr, zz, psi_pred, levels=10, cmap='viridis')\n",
    "    axs[4].set_title(\"Contours\")\n",
    "    axs[4].set_aspect('equal')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
