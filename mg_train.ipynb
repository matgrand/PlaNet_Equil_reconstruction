{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scipy.io as sio\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"mps\") # apple silicon\n",
    "# device = torch.device(\"cpu\") # cpu\n",
    "# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\") # nvidia\n",
    "print(f'device: {device}')\n",
    "\n",
    "def to_tensor(x, device=torch.device(\"cpu\")): return torch.tensor(x, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download datasets from gdrive\n",
    "# import gdown\n",
    "# gdown.download(id=\"1-5KP7_OYIvDD_QXvIr5sDihVxZx1qJCN\", output='mg_data/ITER_like_equilibrium_dataset_sample.mat', quiet=False)\n",
    "# gdown.download(id=\"1Gn_OrMzxPRkTk-i77--HiWmWZyd8i8ue\", output='mg_data/ITER_like_equilibrium_dataset.mat', quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_DS_PATH = \"mg_data/ITER_like_equilibrium_dataset_sample.mat\" # sample dataset\n",
    "FULL_DS_PATH = 'mg_data/ITER_like_equilibrium_dataset.mat' # full dataset\n",
    "MODEL_SAVE_PATH = \"mg_data/mg_planet.pth\"\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 3e-3\n",
    "USE_CURRENTS = True\n",
    "USE_PROFILES = False\n",
    "USE_MAGNETIC = False\n",
    "INPUT_SIZE = int(USE_CURRENTS)*14 + int(USE_PROFILES)*202 + int(USE_MAGNETIC)*187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlaNetDataset(Dataset):\n",
    "    def __init__(self, ds_path):\n",
    "        ds = sio.loadmat(ds_path)\n",
    "        # output: magnetic flux, transposed (matlab is column-major)\n",
    "        self.psi = to_tensor(ds[\"DB_psi_pixel_test_ConvNet\"].transpose(0, 2, 1)) # (n, 64, 64)\n",
    "        # inputs: radial and vertical position of pixels (for plotting only rn) + currents + measurements + profiles \n",
    "        self.rr_pix = ds[\"RR_pixels\"] # radial position of pixels (64, 64)\n",
    "        self.zz_pix = ds[\"ZZ_pixels\"] # vertical position of pixels (64, 64)\n",
    "        self.currs = ds[\"DB_coils_curr_test_ConvNet\"] # input currents (n, 14)\n",
    "        self.magn_meas = ds[\"DB_meas_Bpickup_test_ConvNet\"] # input magnetic measurements (n, 187)\n",
    "        self.f_profile = ds[\"DB_f_test_ConvNet\"] # input profiles (n, 101)\n",
    "        self.p_profile = ds[\"DB_p_test_ConvNet\"] # input profiles (n, 101)\n",
    "        inputs = []\n",
    "        if USE_CURRENTS: inputs.append(to_tensor(self.currs)) # (n, 14)\n",
    "        if USE_MAGNETIC: inputs.append(to_tensor(self.magn_meas)) # (n, 187)\n",
    "        if USE_PROFILES: inputs.append(torch.cat((to_tensor(self.f_profile), to_tensor(self.p_profile)), 1)) # (n, 202)\n",
    "        self.inputs = torch.cat(inputs, 1) # (n, 403)\n",
    "    def __len__(self): return len(self.psi)\n",
    "    def __getitem__(self, idx): return self.inputs[idx], self.psi[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset\n",
    "ds = PlaNetDataset(SAMPLE_DS_PATH)\n",
    "print(f\"Dataset length: {len(ds)}\")\n",
    "print(f\"Input shape: {ds[0][0].shape}\")\n",
    "print(f\"Output shape: {ds[0][1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PlaNet(torch.nn.Module): # simple fully connected neural network > weak > loss:33 > converges to a constant\n",
    "#     def __init__(self):\n",
    "#         super(PlaNet, self).__init__()\n",
    "#         self.n = 8\n",
    "#         self.fc1 = torch.nn.Linear(INPUT_SIZE, self.n)\n",
    "#         self.fc2 = torch.nn.Linear(self.n, self.n)\n",
    "#         self.fc3 = torch.nn.Linear(self.n, 64*64)\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = torch.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         x = x.view(-1, 64, 64)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PlaNet(torch.nn.Module): # transpose convolutional neural network > stronger, fast, but artifacts > loss:0.49\n",
    "#     def __init__(self):\n",
    "#         super(PlaNet, self).__init__()\n",
    "#         self.n = n = 4\n",
    "#         self.fc = torch.nn.Sequential(\n",
    "#             torch.nn.Linear(INPUT_SIZE, 8*n),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.Linear(8*n, 16*n),\n",
    "#             torch.nn.ReLU(),\n",
    "#         )\n",
    "#         self.unconv = torch.nn.Sequential(\n",
    "#             torch.nn.ConvTranspose2d(16*n, 8*n, kernel_size=3),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.BatchNorm2d(8*n), # batch normalization\n",
    "#             torch.nn.ConvTranspose2d(8*n, 4*n, kernel_size=3, stride=2),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.ConvTranspose2d(4*n, 2*n, kernel_size=3, stride=2),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.ConvTranspose2d(2*n, n, kernel_size=3, stride=2),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.ConvTranspose2d(n, 1, kernel_size=4, stride=2),\n",
    "#         )\n",
    "#     def forward(self, x):\n",
    "#         x = self.fc(x)\n",
    "#         x = x.view(-1, 16*self.n, 1, 1)\n",
    "#         x = self.unconv(x)\n",
    "#         x = x.view(-1, 64, 64)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlaNet(torch.nn.Module): # upsample convolutional neural network > slower > but smoother\n",
    "    def __init__(self):\n",
    "        super(PlaNet, self).__init__()\n",
    "        self.interp = 'bilinear' # 'nearest' or 'bilinear'\n",
    "        self.n = n = 4\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(INPUT_SIZE, 8*n),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(8*n, 16*n),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        self.unconv = torch.nn.Sequential(\n",
    "            torch.nn.Upsample(scale_factor=4, mode=self.interp),\n",
    "            torch.nn.Conv2d(16*n, 8*n, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(8*n), # batch normalization\n",
    "            torch.nn.Upsample(scale_factor=2, mode=self.interp),\n",
    "            torch.nn.Conv2d(8*n, 4*n, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Upsample(scale_factor=2, mode=self.interp),\n",
    "            torch.nn.Conv2d(4*n, 2*n, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Upsample(scale_factor=2, mode=self.interp),\n",
    "            torch.nn.Conv2d(2*n, n, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Upsample(scale_factor=2, mode=self.interp),\n",
    "            torch.nn.Conv2d(n, 1, kernel_size=3, padding=1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, 16*self.n, 1, 1)\n",
    "        x = self.unconv(x)\n",
    "        x = x.view(-1, 64, 64)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "model = PlaNet()\n",
    "x = torch.randn(1, INPUT_SIZE)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "y = model(x)\n",
    "print(f\"Output shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = PlaNetDataset(FULL_DS_PATH), PlaNetDataset(SAMPLE_DS_PATH)\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True) # initialize DataLoader\n",
    "val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)  \n",
    "model = PlaNet()  # instantiate model\n",
    "model.to(device) # move model to device\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = torch.nn.MSELoss() # Mean Squared Error Loss\n",
    "best_loss = float('inf') # initialize best loss\n",
    "for epoch in range(EPOCHS): \n",
    "    epoch_time = time()\n",
    "    model.train()\n",
    "    trainloss, evalloss = [], []\n",
    "    # for input_currs, psi in tqdm(train_dl, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=False):\n",
    "    for input_currs, psi in train_dl:\n",
    "        input_currs, psi = input_currs.to(device), psi.to(device) # move to device\n",
    "        optimizer.zero_grad()\n",
    "        psi_pred = model(input_currs)\n",
    "        loss = loss_fn(psi_pred, psi)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        trainloss.append(loss.item())\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for input_currs, psi in val_dl:\n",
    "            input_currs, psi = input_currs.to(device), psi.to(device) # move to device\n",
    "            psi_pred = model(input_currs)\n",
    "            loss = loss_fn(psi_pred, psi)\n",
    "            evalloss.append(loss.item())\n",
    "    print(f\"Ep {epoch+1}: Train Loss: {sum(trainloss)/len(trainloss):.4f}, Eval Loss: {sum(evalloss)/len(evalloss):.4f}, Time: {time()-epoch_time:.2f}s,\", end=\" \")\n",
    "    if sum(evalloss)/len(evalloss) < best_loss:\n",
    "        best_loss = sum(evalloss)/len(evalloss)\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        print(\"new best\")\n",
    "    else: print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PlaNet()\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "model.eval()\n",
    "ds = PlaNetDataset(SAMPLE_DS_PATH)\n",
    "for i in np.random.randint(0, len(ds), 10):  \n",
    "    input_currs, psi = ds[i]\n",
    "    psi_pred = model(input_currs.unsqueeze(0))\n",
    "    psi_pred = psi_pred.detach().numpy().reshape(64, 64)\n",
    "    psi = psi.detach().numpy().reshape(64, 64)\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(15, 5))\n",
    "    ext = [ds.rr_pix.min(), ds.rr_pix.max(), ds.zz_pix.min(), ds.zz_pix.max()]\n",
    "    rr, zz = ds.rr_pix, ds.zz_pix  # radial and vertical positions of pixels\n",
    "    bmin, bmax = np.min([psi, psi_pred]), np.max([psi, psi_pred])\n",
    "    err = np.abs(psi - psi_pred)*100/abs(bmax - bmin)\n",
    "    # err = np.abs(psi - psi_pred)*100/abs((psi + psi_pred)/2)\n",
    "    err_mse = (psi - psi_pred)**2\n",
    "\n",
    "    im0 = axs[0].imshow(psi, extent=ext, vmin=bmin, vmax=bmax)\n",
    "    axs[0].set_title(\"Actual\")\n",
    "    axs[0].set_aspect('equal')\n",
    "    fig.colorbar(im0, ax=axs[0]) \n",
    "\n",
    "    im1 = axs[1].imshow(psi_pred, extent=ext, vmin=bmin, vmax=bmax)\n",
    "    axs[1].set_title(\"Predicted\")\n",
    "    axs[1].set_aspect('equal')\n",
    "    fig.colorbar(im1, ax=axs[1])\n",
    "\n",
    "    im2 = axs[2].imshow(err, extent=ext, vmin=0, vmax=5)\n",
    "    axs[2].set_title(\"Error\")\n",
    "    axs[2].set_aspect('equal')\n",
    "    fig.colorbar(im2, ax=axs[2])\n",
    "\n",
    "    im3 = axs[3].imshow(err_mse, extent=ext, vmin=0, vmax=0.5)\n",
    "    axs[3].set_title(\"MSE\")\n",
    "    axs[3].set_aspect('equal')\n",
    "    fig.colorbar(im3, ax=axs[3])\n",
    "\n",
    "    c0 = axs[4].contour(rr, zz, psi, levels=15, cmap='viridis', linestyles='dashed')\n",
    "    c1 = axs[4].contour(rr, zz, psi_pred, levels=10, cmap='viridis')\n",
    "    axs[4].set_title(\"Contours\")\n",
    "    axs[4].set_aspect('equal')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
