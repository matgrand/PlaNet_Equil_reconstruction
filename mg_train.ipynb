{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Prepapre dataset with the prepare_dataset notebook, before running this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import scipy.io as sio\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from utils import calc_gso_batch\n",
    "\n",
    "device = torch.device(\"mps\") # apple silicon\n",
    "# device = torch.device(\"cpu\") # cpu\n",
    "# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\") # nvidia\n",
    "print(f'device: {device}')\n",
    "\n",
    "def to_tensor(x, device=torch.device(\"cpu\")): return torch.tensor(x, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best MSE loss: 0.087"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = \"mg_data/mg_planet.pth\"\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 3e-3\n",
    "USE_CURRENTS = True\n",
    "USE_PROFILES = False\n",
    "USE_MAGNETIC = True\n",
    "INPUT_SIZE = int(USE_CURRENTS)*14 + int(USE_PROFILES)*202 + int(USE_MAGNETIC)*187\n",
    "TRAIN_DS_PATH = \"data/train_ds.mat\"\n",
    "EVAL_DS_PATH = \"data/eval_ds.mat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mean current: -10183.76, std current: 34209.11\n",
    "- mean magnetic: -0.20, std magnetic: 0.58\n",
    "- mean f_profile: 33.13, std f_profile: 0.28\n",
    "- mean p_profile: 9654.42, std p_profile: 8788.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlaNetDataset(Dataset):\n",
    "    def __init__(self, ds_mat_path):\n",
    "        ds_mat = sio.loadmat(ds_mat_path)\n",
    "        # output: magnetic flux, transposed (matlab is column-major)\n",
    "        self.psi = to_tensor(ds_mat[\"psi\"]).view(-1, 1, 64, 64)\n",
    "        # inputs: radial and vertical position of pixels (for plotting only rn) + currents + measurements + profiles \n",
    "        self.rr = to_tensor(ds_mat[\"rr\"]).view(-1,1,64,64) # radial position of pixels (64, 64)\n",
    "        self.zz = to_tensor(ds_mat[\"zz\"]).view(-1,1,64,64) # vertical position of pixels (64, 64)\n",
    "        self.currs = ds_mat[\"currs\"] # input currents (n, 14)\n",
    "        self.magnetic = ds_mat[\"magnetic\"] # input magnetic measurements (n, 187)\n",
    "        self.f_profile = ds_mat[\"f_profiles\"] # input profiles (n, 101)\n",
    "        self.p_profile = ds_mat[\"p_profiles\"] # input profiles (n, 101)\n",
    "        inputs = [] # add the normalized inputs to the list\n",
    "        if USE_CURRENTS: inputs.append((to_tensor(self.currs)+10183)/34209) # (n, 14)\n",
    "        if USE_MAGNETIC: inputs.append((to_tensor(self.magnetic)+0.2)/0.58) # (n, 187)\n",
    "        if USE_PROFILES: inputs.append(torch.cat(((to_tensor(self.f_profile)-33.13)/0.28, \n",
    "                                                  (to_tensor(self.p_profile)-9654)/8788), 1)) # (n, 202)\n",
    "        self.inputs = torch.cat(inputs, 1) # (n, 403)\n",
    "    def __len__(self): return len(self.psi)\n",
    "    def __getitem__(self, idx): return self.inputs[idx], self.psi[idx], self.rr[idx], self.zz[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset\n",
    "ds = PlaNetDataset(EVAL_DS_PATH)\n",
    "print(f\"Dataset length: {len(ds)}\")\n",
    "print(f\"Input shape: {ds[0][0].shape}\")\n",
    "print(f\"Output shape: {ds[0][1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PlaNet(nn.Module): # simple fully connected neural network > weak > loss:33 > converges to a constant\n",
    "#     def __init__(self):\n",
    "#         super(PlaNet, self).__init__()\n",
    "#         self.n = 8\n",
    "#         self.fc1 = nn.Linear(INPUT_SIZE, self.n)\n",
    "#         self.fc2 = nn.Linear(self.n, self.n)\n",
    "#         self.fc3 = nn.Linear(self.n, 64*64)\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = torch.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         x = x.view(-1, 64, 64)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PlaNet(nn.Module): # transpose convolutional neural network > stronger, fast, but artifacts\n",
    "#     def __init__(self):\n",
    "#         super(PlaNet, self).__init__()\n",
    "#         self.n = n = 4\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(INPUT_SIZE, 8*n),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(8*n, 16*n),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "#         self.unconv = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(16*n, 8*n, kernel_size=3),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm2d(8*n), # batch normalization\n",
    "#             nn.ConvTranspose2d(8*n, 4*n, kernel_size=3, stride=2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.ConvTranspose2d(4*n, 2*n, kernel_size=3, stride=2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.ConvTranspose2d(2*n, n, kernel_size=3, stride=2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.ConvTranspose2d(n, 1, kernel_size=4, stride=2),\n",
    "#         )\n",
    "#     def forward(self, x):\n",
    "#         x = self.fc(x)\n",
    "#         x = x.view(-1, 16*self.n, 1, 1)\n",
    "#         x = self.unconv(x)\n",
    "#         x = x.view(-1, 64, 64)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlaNet(nn.Module): # upsample convolutional neural network > slower > but smoother\n",
    "    def __init__(self):\n",
    "        super(PlaNet, self).__init__()\n",
    "        self.interp = 'bilinear' # 'nearest' or 'bilinear'\n",
    "        self.n = n = 2\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(INPUT_SIZE, 8*n),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8*n, 16*n),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.unconv = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=4, mode=self.interp),\n",
    "            nn.Conv2d(16*n, 8*n, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(8*n), # batch normalization\n",
    "            nn.Upsample(scale_factor=2, mode=self.interp),\n",
    "            nn.Conv2d(8*n, 4*n, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode=self.interp),\n",
    "            nn.Conv2d(4*n, 2*n, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode=self.interp),\n",
    "            nn.Conv2d(2*n, n, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode=self.interp),\n",
    "            nn.Conv2d(n, 1, kernel_size=3, padding=1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, 16*self.n, 1, 1)\n",
    "        x = self.unconv(x)\n",
    "        # x = x.view(-1, 64, 64)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "model = PlaNet()\n",
    "x = torch.randn(1, INPUT_SIZE)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "y = model(x)\n",
    "print(f\"Output shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = PlaNetDataset(TRAIN_DS_PATH), PlaNetDataset(EVAL_DS_PATH) # initialize datasets\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True) # initialize DataLoader\n",
    "val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)  \n",
    "model = PlaNet()  # instantiate model\n",
    "model.to(device) # move model to device\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = nn.MSELoss() # Mean Squared Error Loss\n",
    "best_loss = float('inf') # initialize best loss\n",
    "for epoch in range(EPOCHS): \n",
    "    epoch_time = time()\n",
    "    model.train()\n",
    "    trainloss, evalloss = [], []\n",
    "    for input_currs, psi, rr, zz in train_dl:\n",
    "        input_currs, psi, rr, zz = input_currs.to(device), psi.to(device), rr.to(device), zz.to(device) # move to device\n",
    "        optimizer.zero_grad()\n",
    "        psi_pred = model(input_currs)\n",
    "        print(f\"psi shape: {psi.shape}, psi_pred shape: {psi_pred.shape}, rr shape: {rr.shape}, zz shape: {zz.shape}\")\n",
    "        gso, gso_pred = calc_gso_batch(psi, rr, zz, device=device), calc_gso_batch(psi_pred, rr, zz, device=device)\n",
    "        mse_loss = loss_fn(psi_pred, psi) # mean squared error loss on psi\n",
    "        gso_loss = loss_fn(gso_pred, gso) # PINN loss on grad shafranov\n",
    "        loss = mse_loss + gso_loss # total loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        trainloss.append((loss.item(), mse_loss.item(), gso_loss.item()))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for input_currs, psi in val_dl:\n",
    "            input_currs, psi = input_currs.to(device), psi.to(device) # move to device\n",
    "            psi_pred = model(input_currs)\n",
    "            gso, gso_pred = calc_gso_batch(psi), calc_gso_batch(psi_pred)\n",
    "            mse_loss = loss_fn(psi_pred, psi)\n",
    "            gso_loss = loss_fn(gso_pred, gso)\n",
    "            loss = mse_loss + gso_loss\n",
    "            evalloss.append((loss.item(), mse_loss.item(), gso_loss.item()))\n",
    "    ttot_loss, tmse_loss, tgso_loss = map(lambda x: sum(x)/len(x), zip(*trainloss))\n",
    "    etot_loss, emse_loss, egso_loss = map(lambda x: sum(x)/len(x), zip(*evalloss))\n",
    "    print(f\"Ep {epoch+1}/{EPOCHS}: Train Loss:{ttot_loss:.4f}, mse {tmse_loss:.4f}, gso {tgso_loss:.4f} ||\" +\n",
    "          f\"Eval Loss:{etot_loss:.4f}, mse {emse_loss:.4f}, gso {egso_loss:.4f}, t:{time()-epoch_time:.2f}s,\", end=\" \")\n",
    "    if etot_loss < best_loss:\n",
    "        best_loss = etot_loss\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        print(\"new best\")\n",
    "    else: print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PlaNet()\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "model.eval()\n",
    "ds = PlaNetDataset(EVAL_DS_PATH)\n",
    "# ds = PlaNetDataset(TRAIN_DS_PATH)\n",
    "for i in np.random.randint(0, len(ds), 10):  \n",
    "    input_currs, psi_ds = ds[i]\n",
    "    psi_pred = model(input_currs.unsqueeze(0))\n",
    "    psi_pred = psi_pred.detach().numpy().reshape(64, 64)\n",
    "    psi_ds = psi_ds.detach().numpy().reshape(64, 64)\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(15, 5))\n",
    "    ext = [ds.rr.min(), ds.rr.max(), ds.zz.min(), ds.zz.max()]\n",
    "    rr, zz = ds.rr, ds.zz  # radial and vertical positions of pixels\n",
    "    bmin, bmax = np.min([psi_ds, psi_pred]), np.max([psi_ds, psi_pred])\n",
    "    err = np.abs(psi_ds - psi_pred)*100/abs(bmax - bmin)\n",
    "    # err = np.abs(psi_ds - psi_pred)*100/abs((psi_ds + psi_pred)/2)\n",
    "    err_mse = (psi_ds - psi_pred)**2\n",
    "\n",
    "    im0 = axs[0].imshow(psi_ds, extent=ext, vmin=bmin, vmax=bmax)\n",
    "    axs[0].set_title(\"Actual\")\n",
    "    axs[0].set_aspect('equal')\n",
    "    fig.colorbar(im0, ax=axs[0]) \n",
    "\n",
    "    im1 = axs[1].imshow(psi_pred, extent=ext, vmin=bmin, vmax=bmax)\n",
    "    axs[1].set_title(\"Predicted\")\n",
    "    axs[1].set_aspect('equal')\n",
    "    fig.colorbar(im1, ax=axs[1])\n",
    "\n",
    "    im2 = axs[2].imshow(err, extent=ext, vmin=0, vmax=5)\n",
    "    axs[2].set_title(\"Error\")\n",
    "    axs[2].set_aspect('equal')\n",
    "    fig.colorbar(im2, ax=axs[2])\n",
    "\n",
    "    im3 = axs[3].imshow(err_mse, extent=ext, vmin=0, vmax=0.5)\n",
    "    axs[3].set_title(\"MSE\")\n",
    "    axs[3].set_aspect('equal')\n",
    "    fig.colorbar(im3, ax=axs[3])\n",
    "\n",
    "    c0 = axs[4].contour(rr, zz, psi_ds, levels=20, cmap='viridis', linestyles='dashed')\n",
    "    c1 = axs[4].contour(rr, zz, psi_pred, levels=20, cmap='viridis')\n",
    "    axs[4].set_title(\"Contours\")\n",
    "    axs[4].set_aspect('equal')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
