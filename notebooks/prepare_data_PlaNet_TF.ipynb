{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4-QHFCjANoh",
        "outputId": "b138cf2a-1e71-461d-b8a3-b6b432d1f72b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('../') # add parent directory to path\n",
        "from src.train.utils_train import calc_laplace_df_dr_ker\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import io\n",
        "import seaborn as sns\n",
        "sns.set_style(\"darkgrid\")\n",
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from time import time\n",
        "from tqdm import tqdm\n",
        "from matplotlib import cm\n",
        "DTYPE = 'float32'\n",
        "full_ds_mat_path = '../data/ITER_like_equilibrium_dataset.mat'\n",
        "sample_ds_mat_path = '../data/ITER_like_equilibrium_dataset_sample.mat'\n",
        "N_SAMPLE_TRAIN = 500  #35000 # they will get multiplied by 2\n",
        "N_SAMPLE_TEST = int(N_SAMPLE_TRAIN * 20 / 80) # 20% of the training data\n",
        "INTERP_METHOD = 'linear' # fast, but less accurate\n",
        "# INTERP_METHOD = 'quintic' # slow, but more accurate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # download datasets from gdrive, # uncomment if you want to download the dataset\n",
        "# import gdown\n",
        "# gdown.download(id=\"1-5KP7_OYIvDD_QXvIr5sDihVxZx1qJCN\", output=full_ds_mat_path, quiet=False)\n",
        "# gdown.download(id=\"1Gn_OrMzxPRkTk-i77--HiWmWZyd8i8ue\", output=sample_ds_mat_path, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove all files and dirs in the data directory except for full_ds_mat_path and sample_ds_mat_path\n",
        "if not os.path.exists('../data'): os.makedirs('../data') # create data directory \n",
        "for file_or_dir in os.listdir('../data'):\n",
        "    fn = os.path.join('../data', file_or_dir)\n",
        "    if os.path.isfile(fn) and fn not in [full_ds_mat_path, sample_ds_mat_path]: os.remove(fn)\n",
        "    elif os.path.isdir(fn): \n",
        "        for root, dirs, files in os.walk(fn, topdown=False):\n",
        "            for name in files:\n",
        "                os.remove(os.path.join(root, name))\n",
        "            for name in dirs:\n",
        "                os.rmdir(os.path.join(root, name))\n",
        "        os.rmdir(fn)\n",
        "    else: print(f\"Skipping {fn}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset from mat file\n",
        "mat_ds = io.loadmat(full_ds_mat_path)\n",
        "DB_psi_pixel_test_ConvNet = mat_ds['DB_psi_pixel_test_ConvNet'].astype(DTYPE)\n",
        "DB_meas_Bpickup_test_ConvNet = mat_ds['DB_meas_Bpickup_test_ConvNet'].astype(DTYPE)\n",
        "DB_coils_curr_test_ConvNet = mat_ds['DB_coils_curr_test_ConvNet'].astype(DTYPE)\n",
        "DB_p_test_ConvNet = mat_ds['DB_p_test_ConvNet'].astype(DTYPE)\n",
        "RR_pixels = mat_ds['RR_pixels'].astype(DTYPE)\n",
        "ZZ_pixels = mat_ds['ZZ_pixels'].astype(DTYPE)\n",
        "DB_res_RHS_pixel_test_ConvNet = mat_ds['DB_res_RHS_pixel_test_ConvNet'].astype(DTYPE)\n",
        "DB_separatrix_200_test_ConvNet = mat_ds['DB_separatrix_200_test_ConvNet'].astype(DTYPE)\n",
        "DB_Jpla_pixel_test_ConvNet = mat_ds['DB_Jpla_pixel_test_ConvNet'].astype(DTYPE)\n",
        "# define the dataset\n",
        "Y_data = DB_psi_pixel_test_ConvNet\n",
        "X_data = np.column_stack((DB_meas_Bpickup_test_ConvNet, DB_coils_curr_test_ConvNet)) #, DB_f_test_ConvNet, DB_p_test_ConvNet ))\n",
        "N = Y_data.shape[0] # number of samples\n",
        "# Save RR_pixels, ZZ_pixels\n",
        "nr,nz = RR_pixels.shape\n",
        "io.savemat(f'../data/data_geo_Dataset_NeuralOpt_super_res_{nr}x{nz}.mat',{'RR_pixels':RR_pixels,'ZZ_pixels':ZZ_pixels})   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "skegHPzf_uoi",
        "outputId": "5eed5ee8-9b06-4ca2-9686-3fad8f9f3629"
      },
      "outputs": [],
      "source": [
        "# plot dataset example\n",
        "for i in range(0,1):\n",
        "    ind_plot = np.random.randint(0,N,1)[0]\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(9, 3), sharey=True)\n",
        "    img = axs[0].contour(RR_pixels,ZZ_pixels,DB_psi_pixel_test_ConvNet[ind_plot,:,:],15)\n",
        "    fig.colorbar(img)\n",
        "    axs[0].plot(DB_separatrix_200_test_ConvNet[ind_plot,:,0],DB_separatrix_200_test_ConvNet[ind_plot,:,1],c='g')\n",
        "    axs[0].axis('equal')\n",
        "    axs[0].set_xlabel('r [m]')\n",
        "    axs[0].set_ylabel('z [m]')\n",
        "    axs[0].set_title('Ψ [Wb] - equil. #{}'.format(ind_plot))\n",
        "    img = axs[1].contourf(RR_pixels,ZZ_pixels,DB_Jpla_pixel_test_ConvNet[ind_plot,:,:],15)\n",
        "    fig.colorbar(img)\n",
        "    axs[1].axis('equal')\n",
        "    axs[1].set_title('$J_Ψ$ [A/m2] - equil. #{}'.format(ind_plot))\n",
        "    axs[1].set_xlabel('r [m]')\n",
        "    axs[1].set_ylabel('z [m]')\n",
        "    axs[1].plot(DB_separatrix_200_test_ConvNet[ind_plot,:,0],DB_separatrix_200_test_ConvNet[ind_plot,:,1],c='g')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot Ψ and GS operator\n",
        "cmap = cm.inferno\n",
        "for i in range(0,1):\n",
        "    ind_plot = np.random.randint(0,N,1)[0]\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(9, 3), sharey=True)\n",
        "    rm, rM, zm, zM = RR_pixels.min(), RR_pixels.max(), ZZ_pixels.min(), ZZ_pixels.max()\n",
        "    img = axs[0].contourf(RR_pixels,ZZ_pixels,DB_psi_pixel_test_ConvNet[ind_plot,:,:],15,cmap=cmap)\n",
        "    axs[0].plot( DB_separatrix_200_test_ConvNet[ind_plot,:,0], DB_separatrix_200_test_ConvNet[ind_plot,:,1], c='g')\n",
        "    axs[0].set_xlim([rm,rM])\n",
        "    axs[0].set_ylim([zm,zM])\n",
        "    axs[0].axis('equal')\n",
        "    axs[0].set_axis_off()\n",
        "    axs[0].set_title('Ψ')\n",
        "    qq = DB_res_RHS_pixel_test_ConvNet[ind_plot,:,:]\n",
        "    img = axs[1].contourf(RR_pixels,ZZ_pixels,qq,15,cmap=cmap)\n",
        "    axs[1].set_title('GS operator')\n",
        "    axs[1].axis('equal')\n",
        "    axs[1].set_xlim([rm,rM])\n",
        "    axs[1].set_ylim([zm,zM])\n",
        "    axs[1].axis('equal')\n",
        "    axs[1].plot(DB_separatrix_200_test_ConvNet[ind_plot,:,0], DB_separatrix_200_test_ConvNet[ind_plot,:,1], c='g')\n",
        "    axs[1].set_axis_off()\n",
        "    # plt.savefig('./figures/equil_and_GSope', dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# utils functions\n",
        "import numpy as np\n",
        "from scipy.interpolate import RegularGridInterpolator\n",
        "\n",
        "def sample_random_subgrids(RR_pixels,ZZ_pixels,nr=64,nz=64):\n",
        "  rm, rM, zm, zM = RR_pixels.min(), RR_pixels.max(), ZZ_pixels.min(), ZZ_pixels.max()\n",
        "  delta_r_min = .33*(rM-rm)\n",
        "  delta_r_max = .75*(rM-rm)\n",
        "  delta_z_min = .2*(zM-zm)\n",
        "  delta_z_max = .75*(zM-zm)\n",
        "  delta_r = np.random.uniform(delta_r_min,delta_r_max,1)\n",
        "  r0 = np.random.uniform(rm,rm+delta_r_max-delta_r,1)\n",
        "  delta_z = np.random.uniform(delta_z_min,delta_z_max,1)\n",
        "  z0 = np.random.uniform(zm,zm+delta_z_max-delta_z,1)\n",
        "  rr = np.linspace(r0,r0+delta_r,nr)\n",
        "  zz = np.linspace(z0,z0+delta_z,nz)\n",
        "  rr_grid, zz_grid = np.meshgrid(rr,zz,indexing='xy')\n",
        "  return rr_grid, zz_grid\n",
        "\n",
        "def get_box_from_grid(rr_grid, zz_grid):\n",
        "  rm, rM, zm, zM = rr_grid.min(), rr_grid.max(), zz_grid.min(), zz_grid.max()\n",
        "  return np.array([[rm,zm],[rM,zm],[rM,zM],[rm,zM],[rm,zm]])\n",
        "\n",
        "def interp_fun(f, RR_pixels, ZZ_pixels, rr_grid, zz_grid, kind='quintic'):\n",
        "  interp_func = RegularGridInterpolator((RR_pixels[0,:], ZZ_pixels[:,0]), f.T, method=kind)\n",
        "  pts = np.column_stack((rr_grid.flatten(), zz_grid.flatten()))\n",
        "  f_int = interp_func(pts).reshape(rr_grid.shape)\n",
        "  return f_int\n",
        "\n",
        "def def_grids_and_interp(f, rhs, RR_pixels, ZZ_pixels, nr=64, nz=64, kind='quintic'):\n",
        "  rr_grid, zz_grid = sample_random_subgrids(RR_pixels,ZZ_pixels,nr,nz)\n",
        "  f_grid = interp_fun(f,RR_pixels,ZZ_pixels,rr_grid, zz_grid,kind=kind)\n",
        "  rhs_grid = interp_fun(rhs,RR_pixels,ZZ_pixels,rr_grid, zz_grid,kind=kind)\n",
        "  return rr_grid, zz_grid, f_grid, rhs_grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 964
        },
        "id": "YtetovJywsby",
        "outputId": "fcccf8de-5995-4623-83ee-fb666f7f9b3d"
      },
      "outputs": [],
      "source": [
        "# test interpolation\n",
        "idx = np.random.randint(0, Y_data.shape[0], 1)[0]\n",
        "f, rhs = Y_data[idx,:,:], DB_res_RHS_pixel_test_ConvNet[idx,:,:]\n",
        "rr_grid, zz_grid = sample_random_subgrids(RR_pixels,ZZ_pixels)\n",
        "box = get_box_from_grid(rr_grid, zz_grid)\n",
        "f_grid = interp_fun(Y_data[idx,:,:], RR_pixels, ZZ_pixels, rr_grid, zz_grid, kind=INTERP_METHOD)\n",
        "rhs_grid = interp_fun(rhs, RR_pixels, ZZ_pixels, rr_grid, zz_grid, kind=INTERP_METHOD)\n",
        "\n",
        "fig,ax = plt.subplots(1,5, figsize=(20,5))\n",
        "ax[0].scatter(RR_pixels, ZZ_pixels, marker='.')\n",
        "ax[0].scatter(rr_grid, zz_grid, marker='.')\n",
        "ax[0].set_aspect('equal')\n",
        "\n",
        "im1 = ax[1].contourf(RR_pixels, ZZ_pixels, f, 20)\n",
        "ax[1].plot(box[:,0],box[:,1])\n",
        "ax[1].set_aspect('equal')\n",
        "\n",
        "im2 = ax[2].contourf(rr_grid, zz_grid, f_grid, 20)\n",
        "ax[2].set_aspect('equal')\n",
        "\n",
        "im3 = ax[3].contourf(RR_pixels, ZZ_pixels, rhs, 20)\n",
        "ax[3].set_aspect('equal')\n",
        "ax[3].plot(box[:,0],box[:,1])\n",
        "\n",
        "im4 = ax[4].contourf(rr_grid, zz_grid, rhs_grid, 20)\n",
        "ax[4].set_aspect('equal')\n",
        "\n",
        "plt.colorbar(im1,ax=ax[1])\n",
        "plt.colorbar(im2,ax=ax[2])\n",
        "plt.colorbar(im3,ax=ax[3])\n",
        "plt.colorbar(im4,ax=ax[4])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "### train-test split 80-20\n",
        "all_ids_shuffled = np.random.permutation(np.arange(N))\n",
        "id_train, id_test = all_ids_shuffled[:int(N*0.8)], all_ids_shuffled[int(N*0.8):]\n",
        "np.save('../data/id_train.npy', id_train)\n",
        "np.save('../data/id_test.npy', id_test)\n",
        "# ### Standardize input data\n",
        "# scaler = StandardScaler()\n",
        "# X_data = scaler.fit_transform(X_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugc2tGbQp6mD",
        "outputId": "6f161b34-9945-49c4-df59-071b20864ed3"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "The full training dataset is ~80k equilibria. We select 35k equilibria on the full grid\n",
        "and 35k equilibria to be resampled on randomly generated sub-grids. These two datasets \n",
        "are then put together ans shuffled.\n",
        "\n",
        "_all_domain -> quantities related to the original grid\n",
        "_super_res -> quantities related to random sub-grids\n",
        "\n",
        "It would be nice to explore how the performance changes using data different from the \n",
        "aforementioned 35k/35k.\n",
        "'''\n",
        "# TODO: change this, generate random subgrids for all the data, not only for the training data, test\n",
        "# data as well, and use much more subgrids\n",
        "np.random.seed(42)\n",
        "ind_all_domain = np.random.choice(id_train,N_SAMPLE_TRAIN)\n",
        "ind_super_res = np.random.choice(id_train,N_SAMPLE_TRAIN)\n",
        "\n",
        "n_all_domain = len(ind_all_domain)\n",
        "n_super_res = len(ind_super_res)\n",
        "\n",
        "print(f'{n_all_domain} equil on the original grid')\n",
        "print(f'{n_super_res} equil on random sub-grids')\n",
        "\n",
        "Y_train_all_domain = Y_data[ind_all_domain,:,:]\n",
        "X_train_all_domain = X_data[ind_all_domain,:]\n",
        "res_RHS_pixel_train_all_domain = DB_res_RHS_pixel_test_ConvNet[ind_all_domain,:,:]\n",
        "\n",
        "y_test_all_domain = Y_data[id_test,:,:]\n",
        "X_test_all_domain = X_data[id_test,:]\n",
        "res_RHS_pixel_test_all_domain = DB_res_RHS_pixel_test_ConvNet[id_test,:,:]\n",
        "\n",
        "f_for_super_res = Y_data[ind_super_res,:,:]\n",
        "rhs_for_super_res = DB_res_RHS_pixel_test_ConvNet[ind_super_res,:,:]\n",
        "\n",
        "X_train_super_res = X_data[ind_super_res,:]\n",
        "Y_train_super_res = np.zeros((n_super_res,64,64), dtype=DTYPE)\n",
        "rhs_train_super_res = np.zeros_like(Y_train_super_res, dtype=DTYPE)\n",
        "RR_grid_super_res = np.zeros_like(Y_train_super_res, dtype=DTYPE)\n",
        "ZZ_grid_super_res = np.zeros_like(Y_train_super_res, dtype=DTYPE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# interpolate f and rhs on random sub-grids, NOTE: very slow if using 'quintic' method/kind\n",
        "t_start = time()\n",
        "for i in tqdm(range(len(f_for_super_res))):\n",
        "    rr_grid, zz_grid, f_grid, rhs_grid = def_grids_and_interp(f_for_super_res[i,...],rhs_for_super_res[i,...],RR_pixels,ZZ_pixels, kind=INTERP_METHOD)\n",
        "    RR_grid_super_res[i,:,:] = rr_grid\n",
        "    ZZ_grid_super_res[i,:,:] = zz_grid\n",
        "    Y_train_super_res[i,:,:] = f_grid\n",
        "    rhs_train_super_res[i,:,:] = rhs_grid\n",
        "t_elapsed = time() - t_start\n",
        "print(f't_elapsed = {t_elapsed}, time_per_step = {t_elapsed/n_super_res}')\n",
        "RR_grid_all_domain = np.tile(RR_pixels,(n_all_domain,1,1))\n",
        "ZZ_grid_all_domain = np.tile(ZZ_pixels,(n_all_domain,1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Check re-sampled equils\n",
        "idx = np.random.randint(0, len(Y_train_super_res), 1)[0]\n",
        "\n",
        "f = f_for_super_res[idx,:,:]\n",
        "rhs = rhs_for_super_res[idx,:,:]\n",
        "rr, zz = RR_grid_super_res[idx,:,:], ZZ_grid_super_res[idx,:,:]\n",
        "RRp, ZZp = RR_pixels, ZZ_pixels\n",
        "box = get_box_from_grid(rr, zz)\n",
        "\n",
        "fig,ax = plt.subplots(1,5, figsize=(22,5))\n",
        "ax[0].scatter(RRp, ZZ_pixels, marker='.')\n",
        "ax[0].plot(box[:,0],box[:,1],c='r')\n",
        "ax[0].set_aspect('equal')\n",
        "\n",
        "im = ax[1].contourf(RRp, ZZp, f, 20)\n",
        "ax[1].set_aspect('equal')\n",
        "ax[1].plot(box[:,0],box[:,1],c='r')\n",
        "plt.colorbar(im,ax=ax[1])\n",
        "im = ax[2].contourf(rr, zz, f_grid, 20)\n",
        "ax[2].set_aspect('equal')\n",
        "plt.colorbar(im,ax=ax[2])\n",
        "\n",
        "im = ax[3].contourf(RRp, ZZp, rhs, 20)\n",
        "ax[3].set_aspect('equal')\n",
        "ax[3].plot(box[:,0],box[:,1],c='r')\n",
        "plt.colorbar(im,ax=ax[3])\n",
        "im = ax[4].contourf(rr, zz, rhs_grid, 20)\n",
        "ax[4].set_aspect('equal')\n",
        "plt.colorbar(im,ax=ax[4])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compute kernels for the GS equation train\n",
        "''' Compute kernels for GS Equation for the qeuils on the sub-grids (dr,dz is grid-dependent), \n",
        "otherwise we would have to compute them on the fly during each training step '''\n",
        "y_train = np.row_stack([Y_train_all_domain,Y_train_super_res])\n",
        "X_train = np.row_stack([X_train_all_domain,X_train_super_res])\n",
        "res_RHS_pixel_train = np.row_stack([res_RHS_pixel_train_all_domain,rhs_train_super_res])\n",
        "RR_pixel_train = np.row_stack([RR_grid_all_domain,RR_grid_super_res])\n",
        "ZZ_pixel_train = np.row_stack([ZZ_grid_all_domain,ZZ_grid_super_res])\n",
        "print(X_train.shape, y_train.shape, res_RHS_pixel_train[:,1:-1,1:-1].shape, RR_pixel_train.shape, ZZ_pixel_train.shape)\n",
        "Laplace_kernel = np.zeros((len(y_train),3,3),dtype=DTYPE)\n",
        "Df_dr_kernel = np.zeros((len(y_train),3,3),dtype=DTYPE)\n",
        "hrs, hzs = RR_pixel_train[:,1,2] - RR_pixel_train[:,1,1], ZZ_pixel_train[:,2,1] - ZZ_pixel_train[:,1,1]\n",
        "for i, (hr, hz) in enumerate(tqdm(zip(hrs, hzs), total=len(hrs))):\n",
        "    Laplace_kernel[i,:,:], Df_dr_kernel[i,:,:] = calc_laplace_df_dr_ker(hr, hz)\n",
        "### Dataset with equilibria on the entire domain\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train, res_RHS_pixel_train[:,1:-1,1:-1], RR_pixel_train, ZZ_pixel_train, Laplace_kernel, Df_dr_kernel)).shuffle(42)#.batch(batch_size=1024)\n",
        "tf.data.Dataset.save(train_ds, f'../data/tf_Dataset_train_NeuralOpt_{nr}x{nz}_{len(X_train)}_samples.data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compute kernels for the GS equation test\n",
        "y_test = y_test_all_domain\n",
        "X_test = X_test_all_domain\n",
        "res_RHS_pixel_test = res_RHS_pixel_test_all_domain\n",
        "RR_pixel_test = np.tile(RR_pixels,(len(X_test),1,1))\n",
        "ZZ_pixel_test = np.tile(ZZ_pixels,(len(X_test),1,1))\n",
        "Laplace_kernel = np.zeros((len(y_test),3,3),dtype=DTYPE)\n",
        "Df_dr_kernel = np.zeros((len(y_test),3,3),dtype=DTYPE)\n",
        "hrs, hzs = RR_pixel_test[:,1,2] - RR_pixel_test[:,1,1], ZZ_pixel_test[:,2,1] - ZZ_pixel_test[:,1,1]\n",
        "for i, (hr, hz) in enumerate(tqdm(zip(hrs, hzs), total=len(hrs))):\n",
        "    Laplace_kernel[i,:,:], Df_dr_kernel[i,:,:] = calc_laplace_df_dr_ker(hr, hz)\n",
        "# Dataset with equilibria on the entire domain\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(( X_test, y_test, res_RHS_pixel_test[:,1:-1,1:-1], RR_pixel_test, ZZ_pixel_test, Laplace_kernel, Df_dr_kernel)).shuffle(42)\n",
        "tf.data.Dataset.save(train_ds, f'../data/tf_Dataset_test_NeuralOpt_{nr}x{nz}_{len(y_test)}_samples.data')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
